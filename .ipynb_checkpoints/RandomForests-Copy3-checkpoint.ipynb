{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Decision trees and Random forests to predict Hearts diseases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pprint import pprint, pformat\n",
    "from anytree import Node, RenderTree #To construct trees.\n",
    "import copy #Will use to deepcopy instances of the Node class.\n",
    "from sklearn.model_selection import KFold #For the K-fold cross validation.\n",
    "import logging\n",
    "logging.basicConfig(level=logging.DEBUG, format='%(message)s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will build a simple logging function to make debugging easier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "global logger\n",
    "logger = logging.getLogger()\n",
    "def log(*args, separator=' ', logger=logger):\n",
    "    '''\n",
    "    Logs args into the console using logger, separating them by separator.\n",
    "    A logger must be defined externally.\n",
    "    '''\n",
    "    str_args = [str(arg) for arg in args]\n",
    "    string = separator.join(str_args)\n",
    "    logger.debug(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[[1. 0.]\n",
      " [0. 1.]] 1\n"
     ]
    }
   ],
   "source": [
    "logger.disabled = False\n",
    "#Example:\n",
    "a = np.eye(2)\n",
    "b = 1\n",
    "log(a,b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>RestBP</th>\n",
       "      <th>Chol</th>\n",
       "      <th>Fbs</th>\n",
       "      <th>RestECG</th>\n",
       "      <th>MaxHR</th>\n",
       "      <th>ExAng</th>\n",
       "      <th>Oldpeak</th>\n",
       "      <th>Slope</th>\n",
       "      <th>Ca</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>299.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>152.000000</td>\n",
       "      <td>54.438944</td>\n",
       "      <td>0.679868</td>\n",
       "      <td>131.689769</td>\n",
       "      <td>246.693069</td>\n",
       "      <td>0.148515</td>\n",
       "      <td>0.990099</td>\n",
       "      <td>149.607261</td>\n",
       "      <td>0.326733</td>\n",
       "      <td>1.039604</td>\n",
       "      <td>1.600660</td>\n",
       "      <td>0.672241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>87.612784</td>\n",
       "      <td>9.038662</td>\n",
       "      <td>0.467299</td>\n",
       "      <td>17.599748</td>\n",
       "      <td>51.776918</td>\n",
       "      <td>0.356198</td>\n",
       "      <td>0.994971</td>\n",
       "      <td>22.875003</td>\n",
       "      <td>0.469794</td>\n",
       "      <td>1.161075</td>\n",
       "      <td>0.616226</td>\n",
       "      <td>0.937438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>94.000000</td>\n",
       "      <td>126.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>76.500000</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>211.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>133.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>152.000000</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>130.000000</td>\n",
       "      <td>241.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>153.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>227.500000</td>\n",
       "      <td>61.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>140.000000</td>\n",
       "      <td>275.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>166.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>77.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>564.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>202.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.200000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0         Age         Sex      RestBP        Chol         Fbs  \\\n",
       "count  303.000000  303.000000  303.000000  303.000000  303.000000  303.000000   \n",
       "mean   152.000000   54.438944    0.679868  131.689769  246.693069    0.148515   \n",
       "std     87.612784    9.038662    0.467299   17.599748   51.776918    0.356198   \n",
       "min      1.000000   29.000000    0.000000   94.000000  126.000000    0.000000   \n",
       "25%     76.500000   48.000000    0.000000  120.000000  211.000000    0.000000   \n",
       "50%    152.000000   56.000000    1.000000  130.000000  241.000000    0.000000   \n",
       "75%    227.500000   61.000000    1.000000  140.000000  275.000000    0.000000   \n",
       "max    303.000000   77.000000    1.000000  200.000000  564.000000    1.000000   \n",
       "\n",
       "          RestECG       MaxHR       ExAng     Oldpeak       Slope          Ca  \n",
       "count  303.000000  303.000000  303.000000  303.000000  303.000000  299.000000  \n",
       "mean     0.990099  149.607261    0.326733    1.039604    1.600660    0.672241  \n",
       "std      0.994971   22.875003    0.469794    1.161075    0.616226    0.937438  \n",
       "min      0.000000   71.000000    0.000000    0.000000    1.000000    0.000000  \n",
       "25%      0.000000  133.500000    0.000000    0.000000    1.000000    0.000000  \n",
       "50%      1.000000  153.000000    0.000000    0.800000    2.000000    0.000000  \n",
       "75%      2.000000  166.000000    1.000000    1.600000    2.000000    1.000000  \n",
       "max      2.000000  202.000000    1.000000    6.200000    3.000000    3.000000  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heart_data = pd.read_csv('Heart.csv')\n",
    "heart_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>ChestPain</th>\n",
       "      <th>RestBP</th>\n",
       "      <th>Chol</th>\n",
       "      <th>Fbs</th>\n",
       "      <th>RestECG</th>\n",
       "      <th>MaxHR</th>\n",
       "      <th>ExAng</th>\n",
       "      <th>Oldpeak</th>\n",
       "      <th>Slope</th>\n",
       "      <th>Ca</th>\n",
       "      <th>Thal</th>\n",
       "      <th>AHD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>typical</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>fixed</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>67</td>\n",
       "      <td>1</td>\n",
       "      <td>asymptomatic</td>\n",
       "      <td>160</td>\n",
       "      <td>286</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>108</td>\n",
       "      <td>1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>67</td>\n",
       "      <td>1</td>\n",
       "      <td>asymptomatic</td>\n",
       "      <td>120</td>\n",
       "      <td>229</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>129</td>\n",
       "      <td>1</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>reversable</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>nonanginal</td>\n",
       "      <td>130</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>nontypical</td>\n",
       "      <td>130</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Age  Sex     ChestPain  RestBP  Chol  Fbs  RestECG  MaxHR  \\\n",
       "0           1   63    1       typical     145   233    1        2    150   \n",
       "1           2   67    1  asymptomatic     160   286    0        2    108   \n",
       "2           3   67    1  asymptomatic     120   229    0        2    129   \n",
       "3           4   37    1    nonanginal     130   250    0        0    187   \n",
       "4           5   41    0    nontypical     130   204    0        2    172   \n",
       "\n",
       "   ExAng  Oldpeak  Slope   Ca        Thal  AHD  \n",
       "0      0      2.3      3  0.0       fixed   No  \n",
       "1      1      1.5      2  3.0      normal  Yes  \n",
       "2      1      2.6      2  2.0  reversable  Yes  \n",
       "3      0      3.5      3  0.0      normal   No  \n",
       "4      0      1.4      1  0.0      normal   No  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heart_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Make a tree constructor based on the algorithm from fig. 18.5 of [Norvig] and/or algorithm 8.1 of [Gareth].\n",
    "2. Allow for both categorical and continuous variables: maybe ask the user to specify what variables are continuous and how many splits to perform on each step. Sklearn does not handle categorical variables super easily, so this can actually be useful. Decide on a stopping criterion, maybe even allow for different ones.\n",
    "3. Understand why pruning works as [Hastie] says and using [Breiman], and then implement it as [Hastie] describes.\n",
    "4. Apply to the data. Maybe even apply on only two variables first and plot the regions as [Gareth] does for the Hitters data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression trees [Gareth]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_split(examples, predictor_to_split_idx, cutpoint):\n",
    "    '''\n",
    "    Performs a binary split on the examples array.\n",
    "    ------------\n",
    "    Parameters:\n",
    "    examples is a (# examples, p+1) numpy array where p is the number of predictors. The last column contains the responses.\n",
    "    Splits the predictor_to_split in two at cutpoint.\n",
    "    ------------\n",
    "    Returns a tuple with two (, p+1) numpy arrays of examples:\n",
    "        1: examples whose predictor_to_split is < cutpoint.\n",
    "        2: examples whose predictor_to_split is >= cutpoint.\n",
    "    '''\n",
    "    predictors_to_split = examples[:, predictor_to_split_idx] #Column vector with the value for the predictor to split for all the examples.\n",
    "    mask = predictors_to_split < cutpoint #Boolean mask with True values where predictor to split < cutpoint.\n",
    "    set1 = examples[mask, :]\n",
    "    set2 = examples[np.logical_not(mask), :] #Selects the examples where predictor to split >= cutpoint.\n",
    "    return set1, set2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Small test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xj values from in set1: [], cutpoint = 1, xj values from in set1: [2 5]\n",
      "xj values from in set1: [2], cutpoint = 3, xj values from in set1: [5]\n",
      "xj values from in set1: [2], cutpoint = 5, xj values from in set1: [5]\n"
     ]
    }
   ],
   "source": [
    "exs = np.array([[1,2,3],[1,5,6]])\n",
    "j = 1 #index of the split variable\n",
    "cutpoints = [1, 3, 5]\n",
    "for s in cutpoints:\n",
    "    set1, set2 = binary_split(exs, j, s)\n",
    "    xj_set1 = set1[:, j] #All the xjs in set1. These should all be < s.\n",
    "    xj_set2 = set2[:, j] #All the xjs in set2. These should all be >= s.\n",
    "    print('xj values from in set1: {}, cutpoint = {}, xj values from in set1: {}'.format(xj_set1, s, xj_set2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exs[0,:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's working!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimal_binary_split(examples, predictors_to_split_indices, grid_step_number=10, debug_prints=False):\n",
    "    '''\n",
    "    Splits the examples array at the best cutpoint and using the best predictor.\n",
    "    ------------\n",
    "    Parameters:\n",
    "    examples is a (# examples, p+1) numpy array where p is the number of predictors. The last column contains the responses.\n",
    "    predictors_to_split_indices is a list containing the indices of the predictors we want to split. It can also be the string 'all', in which case we split all the predictors.\n",
    "    ------------\n",
    "    Returns:\n",
    "    Tuple (j, s, smallest_cost):\n",
    "        1) index of the predictor that was split.\n",
    "        2) chosen cutpoint for the split.\n",
    "        3) cost of the chosen (thus optimal) split.\n",
    "    '''\n",
    "    ###Set up logger\n",
    "    global logger\n",
    "    if debug_prints:\n",
    "        logger.disabled = False\n",
    "    else:\n",
    "        logger.disabled = True #Must write this explicitly to not have problems when running inside other functions.\n",
    "    ###\n",
    "    p = len(examples[0, :-1]) #Number of predictors.\n",
    "    smallest_cost = 100000\n",
    "    best_split = (0, 0, smallest_cost) #placeholder for best_split.\n",
    "    for j in predictors_to_split_indices:\n",
    "        #Construct array of cutpoints:\n",
    "        max_cutpoint =  max(examples[:, j]) \n",
    "        step = (max_cutpoint - min(examples[:,j]))/grid_step_number #grid step\n",
    "        min_cutpoint =  min(examples[:, j]) + step  #We do not want to include min(examples[:,j]) itself, since that would lead to cases with no points 'on the left' because of how binary_split() was defined.\n",
    "        if min_cutpoint == max_cutpoint: #Examples have the same jth predictor value, so no split can be made, so we abort the split.\n",
    "            log('Skip j = {}'.format(j))\n",
    "            continue #Goes to the top of this loop again.\n",
    "        cutpoints = np.linspace(min_cutpoint, max_cutpoint, grid_step_number) \n",
    "        log('Cutpoints for j={}: {}, step: {}'.format(j, cutpoints, step))\n",
    "        for s in cutpoints:\n",
    "            set1, set2 = binary_split(examples, j, s)\n",
    "            log('s,j: {}, {} \\n set1 --- set2: {} --- {}'.format(s,j, set1, set2))\n",
    "            y_1 = set1[:, p]; y_2 = set2[:, p] #Extract the responses.\n",
    "            y1_estimate = np.average(y_1); y2_estimate = np.average(y_2) #Estimates will simply be the averages.\n",
    "            cost = np.sum(np.square(y_1 - y1_estimate)) + np.sum(np.square(y_2 - y2_estimate))\n",
    "            if cost < smallest_cost:\n",
    "                log('NEW COST: {}'.format(cost))\n",
    "                smallest_cost = cost\n",
    "                best_split = (j, s, smallest_cost) #Store info about this iteration.\n",
    "    return best_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skip j = 0\n",
      "Cutpoints for j=1: [2.3 2.6 2.9 3.2 3.5 3.8 4.1 4.4 4.7 5. ], step: 0.3\n",
      "s,j: 2.3, 1 \n",
      " set1 --- set2: [[1 2 8]] --- [[1 4 7]\n",
      " [1 5 2]]\n",
      "NEW COST: 12.5\n",
      "s,j: 2.5999999999999996, 1 \n",
      " set1 --- set2: [[1 2 8]] --- [[1 4 7]\n",
      " [1 5 2]]\n",
      "s,j: 2.9, 1 \n",
      " set1 --- set2: [[1 2 8]] --- [[1 4 7]\n",
      " [1 5 2]]\n",
      "s,j: 3.2, 1 \n",
      " set1 --- set2: [[1 2 8]] --- [[1 4 7]\n",
      " [1 5 2]]\n",
      "s,j: 3.5, 1 \n",
      " set1 --- set2: [[1 2 8]] --- [[1 4 7]\n",
      " [1 5 2]]\n",
      "s,j: 3.8, 1 \n",
      " set1 --- set2: [[1 2 8]] --- [[1 4 7]\n",
      " [1 5 2]]\n",
      "s,j: 4.1, 1 \n",
      " set1 --- set2: [[1 4 7]\n",
      " [1 2 8]] --- [[1 5 2]]\n",
      "NEW COST: 0.5\n",
      "s,j: 4.4, 1 \n",
      " set1 --- set2: [[1 4 7]\n",
      " [1 2 8]] --- [[1 5 2]]\n",
      "s,j: 4.7, 1 \n",
      " set1 --- set2: [[1 4 7]\n",
      " [1 2 8]] --- [[1 5 2]]\n",
      "s,j: 5.0, 1 \n",
      " set1 --- set2: [[1 4 7]\n",
      " [1 2 8]] --- [[1 5 2]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Examples: \n",
      " [[1 4 7]\n",
      " [1 5 2]\n",
      " [1 2 8]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1, 4.1, 0.5)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Example.\n",
    "exs = np.array([[1,4,7],[1,5,2],[1,2,8]])\n",
    "print('Examples: \\n {}'.format(exs))\n",
    "p = len(exs[0, :-1]) #Number of predictors.\n",
    "predictors_to_split_indices = range(p) #List with indices of predictors to split.\n",
    "optimal_binary_split(exs, predictors_to_split_indices, debug_prints=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the function behaves as expected, clumping together the first and third rows, which indeed have the closest response values 7 and 8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recursive_binary_split(examples, max_leaf_population, predictors_to_split_indices='all', grid_step_number=10, debug_prints=False, deep_debug_prints = False):\n",
    "    '''\n",
    "    Recursively splits the examples array, building a decision tree with binary splits and stopping when every leaf contains less than max_leaf_population examples.\n",
    "    ------------\n",
    "    Parameters:\n",
    "    examples is a (# examples, p+1) numpy array where p is the number of predictors. The last column contains the responses.\n",
    "    predictors_to_split_indices is a list containing the indices of the predictors we want to split. It can also be the string 'all', in which case we split all the predictors.\n",
    "    ------------\n",
    "    Returns:\n",
    "    tree_root: the root node of the resulting tree.\n",
    "    '''\n",
    "    ###Set up logger\n",
    "    global logger\n",
    "    if debug_prints:\n",
    "        logger.disabled = False\n",
    "    else:\n",
    "        logger.disabled = True #Must write this explicitly to not have problems when running inside other functions.\n",
    "    logger_bool = logger.disabled\n",
    "    ###\n",
    "    p = len(examples[0, :-1]) #Number of predictors.\n",
    "    if predictors_to_split_indices == 'all':\n",
    "        predictors_to_split_indices = range(p) #List with indices of predictors to split.\n",
    "    #Initialize variables.\n",
    "    tree_root = Node(examples, id='root'); tree_root.region = [] #Initialize tree with the root node.\n",
    "    top_leaf_population = len(examples[:,0])\n",
    "    while top_leaf_population >= max_leaf_population:\n",
    "        #Create list of region leaf nodes.\n",
    "        regions = tree_root.leaves\n",
    "        #Select best region to make split, and split parameters.\n",
    "        splits_info = [((idx, region), optimal_binary_split(region.name, predictors_to_split_indices, grid_step_number=grid_step_number, debug_prints=deep_debug_prints)) for (idx,region) in enumerate(regions) if region.name.shape[0]>0] #The if statement ensures there's at least one example. region.name is the array of examples in the region node.\n",
    "        logger.disabled = logger_bool #Restore logger.disable (may have been changed by optimal_binary_split()).\n",
    "        #Find best split.\n",
    "        costs = [info[1][2] for info in splits_info] #info[1] is tuple (j,s,smallest_cost)\n",
    "        min_idx = np.argmin(costs)\n",
    "        best_split = splits_info[min_idx] #Tuple ((idx, region), (j,s,cost))\n",
    "        #We now make the actual split.\n",
    "        idx_region, region = best_split[0]\n",
    "        j = best_split[1][0]\n",
    "        s = best_split[1][1]\n",
    "        R1, R2 = binary_split(region.name, j, s)\n",
    "        #Create new leaves, update tree and leaf pop:\n",
    "        leaf1 = Node(R1, id='x_{} < {}'.format(j,s)); leaf1.region = region.region + [(j, s, True)] #Add new constraints to the parent's contraints.\n",
    "        leaf2 = Node(R2, id='x_{} >= {}'.format(j,s)); leaf2.region = region.region + [(j, s, False)]\n",
    "        region.children += (leaf1, leaf2,)\n",
    "        top_leaf_population = max([len(leaf.name[:,0]) for leaf in tree_root.leaves])\n",
    "        #Logs for debugging:\n",
    "        log('--------------------')\n",
    "        log('Two representations of the current tree:'); log('')\n",
    "        log(RenderTree(tree_root).by_attr('id'));  log('')\n",
    "        log(RenderTree(tree_root).by_attr('name'));  log('')\n",
    "        log('Current max leaf population: {}'.format(top_leaf_population))\n",
    "    return tree_root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "Two representations of the current tree:\n",
      "\n",
      "root\n",
      "├── x_1 < 4.1\n",
      "└── x_1 >= 4.1\n",
      "\n",
      "[[1 4 7]\n",
      " [1 5 2]\n",
      " [1 2 8]]\n",
      "├── [[1 4 7]\n",
      "│    [1 2 8]]\n",
      "└── [[1 5 2]]\n",
      "\n",
      "Current max leaf population: 2\n",
      "--------------------\n",
      "Two representations of the current tree:\n",
      "\n",
      "root\n",
      "├── x_1 < 4.1\n",
      "│   ├── x_1 < 2.2\n",
      "│   └── x_1 >= 2.2\n",
      "└── x_1 >= 4.1\n",
      "\n",
      "[[1 4 7]\n",
      " [1 5 2]\n",
      " [1 2 8]]\n",
      "├── [[1 4 7]\n",
      "│    [1 2 8]]\n",
      "│   ├── [[1 2 8]]\n",
      "│   └── [[1 4 7]]\n",
      "└── [[1 5 2]]\n",
      "\n",
      "Current max leaf population: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Examples: \n",
      " [[1 4 7]\n",
      " [1 5 2]\n",
      " [1 2 8]]\n",
      "\n",
      " The final tree: \n",
      " [[1 4 7]\n",
      " [1 5 2]\n",
      " [1 2 8]]\n",
      "├── [[1 4 7]\n",
      "│    [1 2 8]]\n",
      "│   ├── [[1 2 8]]\n",
      "│   └── [[1 4 7]]\n",
      "└── [[1 5 2]]\n",
      "\n",
      " The final tree (encoded) region of the first leaf: \n",
      " [(1, 4.1, True), (1, 2.2, True)]\n"
     ]
    }
   ],
   "source": [
    "#Example.\n",
    "exs = np.array([[1,4,7],[1,5,2],[1,2,8]])\n",
    "print('Examples: \\n {}'.format(exs))\n",
    "tree_root = recursive_binary_split(exs, 2, debug_prints=True)\n",
    "print('\\n The final tree: \\n', RenderTree(tree_root).by_attr('name'))\n",
    "print('\\n The final tree (encoded) region of the first leaf: \\n', tree_root.leaves[0].region)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tree prunning [Hastie]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tree $T_0$ created using recursive binary split will probably overfit. The strategy is to simplify the model by finding an appropriate subtree $T$ of $T_0$ by pruning $T$ using *cost-complexity-pruning*, which we'll briefly explain here.\n",
    "\n",
    "The *cost complexity criterion* is defined by\n",
    "$$\n",
    "C_\\alpha(T) = \\sum_{m=1}^{\\vert T \\vert} \\sum_{i\\in I_m} (y_i - \\hat{y}_{R_m})^2 + \\alpha \\vert T \\vert\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where $\\vert T \\vert$ is the number of leaves of $T$, $I_m$ is the indexing set of the region $R_m$ (*i.e.* $R_m = \\{x_i \\in \\text{examples}: i\\in I_m\\}$), $\\hat{y}_{R_m}$ is the predicted response in $R_m$ (in our case $\\hat{y}_{R_m}$ is just the mean $\\mu_{R_m}$), and $\\alpha\\in \\mathbb{R}^+$ controls the size of the tree."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now want to find the subtree $T_\\alpha\\subseteq T_0$ that minimizes $C_\\alpha(T)$. Notice that for $\\alpha = 0$ the minimizing subtree is $T_0$ itself, thus justifying the notation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be shown [Breiman] that for all $\\alpha\\in\\mathbb{R}^+$ there is a unique smallest subtree $T_\\alpha$ that minimizes the cost complexity criterion, and to find it one can use *weakest link pruning*: starting from the bottom (the leaves) of the tree $T_0$, undo the split which has less impact (decreases the least) on the $\\sum_{m=1}^{\\vert T \\vert} \\sum_{i\\in I_m} (y_i - \\hat{y}_{R_m})^2$ part of the cost complexity criterion, obtaining a subtree; keep doing this until you're left only with the root of the tree.\n",
    "This gives us a sequence of subtrees of $T_0$, and it turns out [Breiman] that this sequence must contain $T_\\alpha$.\n",
    "\n",
    "This means that we can simply implement weakest link pruning to obtain a sequence of subtrees and find the one which minimizes $C_\\alpha$. That subtree must be $T_\\alpha$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost_complexity_criterion(alpha, regions):\n",
    "    '''\n",
    "    Computes the cost complexity criterion using the average as the in-region prediction.\n",
    "    ------------\n",
    "    Parameters:\n",
    "    alpha >= 0.\n",
    "    regions is a list of 'regions', each 'region' being an array of examples.\n",
    "    ------------\n",
    "    Returns:\n",
    "    cost: real positive number.\n",
    "    '''\n",
    "    cost = 0\n",
    "    leaf_number = len(regions)\n",
    "    for region in regions:\n",
    "        ys = region[:,-1] #Extract responses.\n",
    "        pred = np.mean(ys) #Decision trees usually predict using the in-region mean.\n",
    "        sq_dev = np.sum(np.square( ys - pred ))\n",
    "        cost += sq_dev + alpha*leaf_number\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "leaves:  [array([[1, 2, 8]]), array([[1, 4, 7]]), array([[1, 5, 2]])]\n",
      "alpha: 0, cost: 0.0\n",
      "alpha: 0.5, cost: 4.5\n",
      "alpha: 1, cost: 9.0\n",
      "alpha: 2, cost: 18.0\n",
      "alpha: 10, cost: 90.0\n",
      "leaves:  [array([[1, 4, 7],\n",
      "       [1, 2, 8]]), array([[1, 5, 2]])]\n",
      "alpha: 0, cost: 0.5\n",
      "alpha: 0.5, cost: 2.5\n",
      "alpha: 1, cost: 4.5\n",
      "alpha: 2, cost: 8.5\n",
      "alpha: 10, cost: 40.5\n"
     ]
    }
   ],
   "source": [
    "#Let's test this on the example from before:\n",
    "alphas = [0, 0.5, 1, 2, 10]\n",
    "example_leaves = recursive_binary_split(exs, 2).leaves\n",
    "leaves = [leaf.name for leaf in example_leaves]\n",
    "print('leaves: ', leaves)\n",
    "for alpha in alphas:\n",
    "    print('alpha: {}, cost: {}'.format(alpha, cost_complexity_criterion(alpha, leaves)) )\n",
    "\n",
    "# But what if we allow for 2 examples per region when splitting?:\n",
    "example_leaves = recursive_binary_split(exs, 3).leaves\n",
    "leaves = [leaf.name for leaf in example_leaves]\n",
    "print('leaves: ', leaves)\n",
    "for alpha in alphas:\n",
    "    print('alpha: {}, cost: {}'.format(alpha, cost_complexity_criterion(alpha, leaves)) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the results make sense: at $\\alpha=0$ the cost is zero (so of course minimum) for the more complex tree (the first one). But for the other values of alpha one sees that the cost of the simpler tree (the second one) gives a lower cost! This is precisely the kind of behavior we wanted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to define weakest link pruning, we will use the fact that each pair of siblings in the tree correspond exactly to a split:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tree: \n",
      " [[1 4 7]\n",
      " [1 5 2]\n",
      " [1 2 8]]\n",
      "├── [[1 4 7]\n",
      "│    [1 2 8]]\n",
      "│   ├── [[1 2 8]]\n",
      "│   └── [[1 4 7]]\n",
      "└── [[1 5 2]] \n",
      "\n",
      "Descendants of the root and their siblings:\n",
      "descendant:\n",
      "[[1 4 7]\n",
      " [1 2 8]]\n",
      "   sibling:[array([[1, 5, 2]])]\n",
      "descendant:\n",
      "[[1 2 8]]\n",
      "   sibling:[array([[1, 4, 7]])]\n",
      "descendant:\n",
      "[[1 4 7]]\n",
      "   sibling:[array([[1, 2, 8]])]\n",
      "descendant:\n",
      "[[1 5 2]]\n",
      "   sibling:[array([[1, 4, 7],\n",
      "       [1, 2, 8]])]\n"
     ]
    }
   ],
   "source": [
    "#Using again the above example:\n",
    "print('Tree: \\n', RenderTree(tree_root).by_attr('name'), '\\n\\nDescendants of the root and their siblings:')\n",
    "for descendant in tree_root.descendants:\n",
    "    print('descendant:\\n{}\\n   sibling:{}'.format(descendant.name, [sib.name for sib in descendant.siblings]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the algorithm of the weakest link pruning (acting on the tree $T$) will:\n",
    "   1. prune away one pair of sibling leaves, creating a temporary subtree $T'$ of $T$.\n",
    "   2. compute the complexity cost criterion of $T'$.\n",
    "   3. repeat 1,2 for all pairs of sibling leaves.\n",
    "   4. select the subtree $T'$ with the lowest cost, and do $T=T'$.\n",
    "   5. repeat 1-4 until $T= \\{\\mathrm{root}\\}$ -- or equivalently until the height of $T$ is 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sibling_pairs(tree_root):\n",
    "    '''\n",
    "    '''\n",
    "    leaves = tree_root.leaves\n",
    "    sib_pairs = []\n",
    "    for leaf in tree_root.leaves:\n",
    "        if any(leaf in pair for pair in sib_pairs): #We don't want duplicates, so we move on to the next leaf if this one is already in a pair.\n",
    "            continue\n",
    "        sib_pairs.append((leaf, leaf.siblings[0])) #Each leaf will have a unique sibling.\n",
    "    return sib_pairs\n",
    "\n",
    "def prune_siblings(sibs):\n",
    "    '''\n",
    "    sibs is tuple.\n",
    "    '''\n",
    "    parent = sibs[0].parent\n",
    "    parent.children = [] #This erases the siblings.\n",
    "    return \n",
    "    \n",
    "    \n",
    "\n",
    "def wl_prun_step(tree_root, alpha): #Contains steps 1-4 of the algorithm.\n",
    "    '''\n",
    "    '''\n",
    "    cost = 100000000\n",
    "    sib_pairs = get_sibling_pairs(tree_root)\n",
    "    for i in range(len(sib_pairs)): #Will go through all leaf sibling pairs. Must do this this way to allow for deep copies on every iteration.\n",
    "        tree_temp = copy.deepcopy(tree_root) #Copy the tree for manipulation.\n",
    "        #Select and prune pair:\n",
    "        sib_pairs_temp = get_sibling_pairs(tree_temp)\n",
    "        pair = sib_pairs_temp[i]\n",
    "        prune_siblings(pair)\n",
    "        #Compute cost of T':\n",
    "        leaves_nodes = tree_temp.leaves\n",
    "        leaves = [leaf.name for leaf in example_leaves] #We must feed arrays to the cost function, not nodes.\n",
    "        cost_temp = cost_complexity_criterion(alpha, leaves)\n",
    "        if cost_temp < cost:\n",
    "            cost = cost_temp\n",
    "            best_tree_temp = copy.deepcopy(tree_temp)\n",
    "    tree_root = copy.deepcopy(best_tree_temp) #Step 4 of the algorithm.\n",
    "    return tree_root\n",
    "    \n",
    "def weakest_link_pruning(tree_root, alpha):\n",
    "    '''\n",
    "    '''\n",
    "    pruning_log = [( copy.deepcopy(tree_root), cost_complexity_criterion(alpha, [leaf.name for leaf in tree_root.leaves]) )]\n",
    "    itr = 0\n",
    "    print('iter: {}\\n{}\\n----------'.format(itr, RenderTree(tree_root).by_attr('id')))\n",
    "    while tree_root.height > 0:\n",
    "        itr += 1\n",
    "        tree_root = wl_prun_step(tree_root, alpha)\n",
    "        print('iter: {}\\n{}\\n----------'.format(itr, RenderTree(tree_root).by_attr('id')))\n",
    "        pruning_log.append(( copy.deepcopy(tree_root), cost_complexity_criterion(alpha, [leaf.name for leaf in tree_root.leaves]) ))\n",
    "    return pruning_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      "├── x_1 < 4.1\n",
      "│   ├── x_1 < 2.2\n",
      "│   └── x_1 >= 2.2\n",
      "└── x_1 >= 4.1\n",
      "\n",
      " Pairs:\n",
      " [(Node('/[[1 4 7]\\n [1 5 2]\\n [1 2 8]]/[[1 4 7]\\n [1 2 8]]/[[1 2 8]]', id='x_1 < 2.2', region=[(1, 4.1, True), (1, 2.2, True)]), Node('/[[1 4 7]\\n [1 5 2]\\n [1 2 8]]/[[1 4 7]\\n [1 2 8]]/[[1 4 7]]', id='x_1 >= 2.2', region=[(1, 4.1, True), (1, 2.2, False)])), (Node('/[[1 4 7]\\n [1 5 2]\\n [1 2 8]]/[[1 5 2]]', id='x_1 >= 4.1', region=[(1, 4.1, False)]), Node('/[[1 4 7]\\n [1 5 2]\\n [1 2 8]]/[[1 4 7]\\n [1 2 8]]', id='x_1 < 4.1', region=[(1, 4.1, True)]))]\n",
      "\n",
      "Deleting the first pair: \n",
      " root\n",
      "├── x_1 < 4.1\n",
      "└── x_1 >= 4.1\n"
     ]
    }
   ],
   "source": [
    "#Test the first and second functions with the example from before:\n",
    "tree_root = recursive_binary_split(exs, 2)\n",
    "tree_og = copy.deepcopy(tree_root)\n",
    "print(RenderTree(tree_root).by_attr('id'))\n",
    "print('\\n Pairs:\\n', get_sibling_pairs(tree_root))\n",
    "pair = get_sibling_pairs(tree_root)[0]\n",
    "prune_siblings(pair)\n",
    "print('\\nDeleting the first pair: \\n', RenderTree(tree_root).by_attr('id'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter: 0\n",
      "root\n",
      "├── x_1 < 4.1\n",
      "│   ├── x_1 < 2.2\n",
      "│   └── x_1 >= 2.2\n",
      "└── x_1 >= 4.1\n",
      "----------\n",
      "iter: 1\n",
      "root\n",
      "├── x_1 < 4.1\n",
      "└── x_1 >= 4.1\n",
      "----------\n",
      "iter: 2\n",
      "root\n",
      "----------\n",
      "----------- Log ----------\n",
      "iter: 0, cost: 7.200000000000001\n",
      "root\n",
      "├── x_1 < 4.1\n",
      "│   ├── x_1 < 2.2\n",
      "│   └── x_1 >= 2.2\n",
      "└── x_1 >= 4.1\n",
      "\n",
      "iter: 1, cost: 3.7\n",
      "root\n",
      "├── x_1 < 4.1\n",
      "└── x_1 >= 4.1\n",
      "\n",
      "iter: 2, cost: 21.466666666666665\n",
      "root\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Test the pruning:\n",
    "tree_root = recursive_binary_split(exs, 2)\n",
    "\n",
    "alpha = 0.8\n",
    "pruning_log = weakest_link_pruning(tree_root, alpha)\n",
    "\n",
    "#See if the log has all the subtress that we expect:\n",
    "print('----------- Log ----------')\n",
    "for idx,(tree,cost) in enumerate(pruning_log):\n",
    "    print('iter: {}, cost: {}\\n{}\\n'.format(idx, cost, RenderTree(tree).by_attr('id')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, we want to select, from the log, the tree with the smallest cost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost_complexity_pruning(tree_root, alpha):\n",
    "    '''\n",
    "    Returns: tuple (best_tree, min_cost)\n",
    "    '''\n",
    "    pruning_log = weakest_link_pruning(tree_root, alpha) #The entries are of type (tree_root, cost)\n",
    "    best_tree, min_cost = min(pruning_log, key=lambda p: p[1]) #  p[1]=cost.\n",
    "    return best_tree, min_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter: 0\n",
      "root\n",
      "├── x_1 < 4.1\n",
      "│   ├── x_1 < 2.2\n",
      "│   └── x_1 >= 2.2\n",
      "└── x_1 >= 4.1\n",
      "----------\n",
      "iter: 1\n",
      "root\n",
      "├── x_1 < 4.1\n",
      "└── x_1 >= 4.1\n",
      "----------\n",
      "iter: 2\n",
      "root\n",
      "----------\n",
      "cost:  3.7 \n",
      "Tree Talpha with alpha=0.8:\n",
      " root\n",
      "├── x_1 < 4.1\n",
      "└── x_1 >= 4.1\n"
     ]
    }
   ],
   "source": [
    "#Bck to the same example as before:\n",
    "tree_root = recursive_binary_split(exs, 2)\n",
    "\n",
    "alpha = 0.8\n",
    "best_tree, min_cost = cost_complexity_pruning(tree_root, alpha)\n",
    "print('cost: ', min_cost, '\\nTree Talpha with alpha=0.8:\\n', RenderTree(best_tree).by_attr('id'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that we obtained the correct $T_\\alpha$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting $\\alpha$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to select a good value for alpha we use $K$-fold cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2] [0]\n",
      "[0 2] [1]\n",
      "[0 1] [2]\n"
     ]
    }
   ],
   "source": [
    "# 3-folding in our example:\n",
    "kf = KFold(n_splits=3)\n",
    "for train_idx, test_idx in kf.split(exs):\n",
    "    print(train_idx, test_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_region(tree_root, x):\n",
    "    '''\n",
    "    x is a one dimensional array.\n",
    "    Returns: leaf (node) corresponding to the region where x is.\n",
    "    '''\n",
    "    leaves = tree_root.leaves\n",
    "    for leaf in leaves:\n",
    "        encoded_region = leaf.region  # [(j,s,smaller?),...,(j,s,smaller?)]\n",
    "        #for j,s,smaller in encoded_region:\n",
    "         #   if (x[j] < s) == smaller: # True if xj<s and smaller=True or if xj>=s and smaller=False. False otherwise.\n",
    "        bools = [ (x[j] < s) == smaller for j,s,smaller in encoded_region ]\n",
    "        if all(bools):\n",
    "            return leaf\n",
    "    return 'x not in the domain?!'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_1 >= 4.1\n",
      "x_1 >= 4.1\n",
      "x_1 < 4.1\n"
     ]
    }
   ],
   "source": [
    "#Test find_region\n",
    "print(find_region(best_tree, [1, 4.2]).id)\n",
    "print(find_region(best_tree, [1, 4.1]).id)\n",
    "print(find_region(best_tree, [1, 4.0]).id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "                \n",
    "def prediction_from_tree(tree_root, xs):\n",
    "    '''\n",
    "    '''\n",
    "    for x in xs:\n",
    "        #Get the region:\n",
    "        region_leaf = find_region(tree_root, x)\n",
    "        region_examples = region_leaf\n",
    "    pass \n",
    "    \n",
    "\n",
    "def choose_alpha(examples, alphas, K, max_leaf_population=3,):\n",
    "    '''\n",
    "    alphas: list of values to test for alpha.\n",
    "    '''\n",
    "    kf = KFold(n_splits=3)\n",
    "    for train_idx, test_idx in kf.split(exs): #Will have K iterations.\n",
    "        train, test = examples[train_idx], examples[test_idx]\n",
    "        tree_root = recursive_binary_split(train, max_leaf_population) #Construct the complex tree T.\n",
    "        #Construct sequence of best subtrees, one for every alpha:\n",
    "        tree_sequence = []\n",
    "        for alpha in alphas:\n",
    "            best_tree, cost = cost_complexity_pruning(tree_root, alpha)\n",
    "            tree_sequence.append((best_tree, cost))\n",
    "        #Compute the errors of these trees on the test set (still one for each alpha).\n",
    "        predictions = []\n",
    "        errors = []\n",
    "    #Average the errors. One average for each alpha.\n",
    "    pass\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References:\n",
    "\n",
    "1. [Hastie]  \n",
    "2. [Norvig]\n",
    "3. [Gareth]\n",
    "4. [Breiman]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

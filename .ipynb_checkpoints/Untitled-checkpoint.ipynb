{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Decision trees and Random forests to predict Hearts diseases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing and visualizing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.read_csv("
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Make a tree constructor based on the algorithm from fig. 18.5 of [Norvig] and/or algorithm 8.1 of [Gareth].\n",
    "2. Allow for both categorical and continuous variables: maybe ask the user to specify what variables are continuous and how many splits to perform on each step. Sklearn does not handle categorical variables super easily, so this can actually be useful. Decide on a stopping criterion, maybe even allow for different ones.\n",
    "3. Understand why pruning works as [Hastie] says and using [Breiman], and then implement it as [Hastie] describes.\n",
    "4. Apply to the data. Maybe even apply on only two variables first and plot the regions as [Gareth] does for the Hitters data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression trees [Gareth]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_split(examples, predictor_to_split_idx, cutpoint):\n",
    "    '''\n",
    "    examples is a (# examples, p+1) numpy array where p is the number of predictors. The last column contains the responses.\n",
    "    Splits the predictor_to_split in two at cutpoint.\n",
    "    Returns a tuple with two (, p+1) numpy arrays of examples:\n",
    "        1: examples whose predictor_to_split is < cutpoint.\n",
    "        2: examples whose predictor_to_split is >= cutpoint.\n",
    "    '''\n",
    "    predictors_to_split = examples[:, predictor_to_split_idx] #Column vector with the value for the predictor to split for all the examples.\n",
    "    mask = predictors_to_split < cutpoint #Boolean mask with True values where predictor to split < cutpoint.\n",
    "    set1 = examples[mask, :]\n",
    "    set2 = examples[np.logical_not(mask), :] #Selects the examples where predictor to split >= cutpoint.\n",
    "    return set1, set2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Small test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2 3]\n",
      " [1 5 6]]\n",
      "xj values from in set1: [], cutpoint = 1, xj values from in set1: [2 5]\n",
      "xj values from in set1: [2], cutpoint = 3, xj values from in set1: [5]\n",
      "xj values from in set1: [2], cutpoint = 5, xj values from in set1: [5]\n"
     ]
    }
   ],
   "source": [
    "exs = np.array([[1,2,3],[1,5,6]])\n",
    "j = 1 #index of the split variable\n",
    "cutpoints = [1, 3, 5]\n",
    "for s in cutpoints:\n",
    "    set1, set2 = binary_split(exs, j, s)\n",
    "    xj_set1 = set1[:, j] #All the xjs in set1. These should all be < s.\n",
    "    xj_set2 = set2[:, j] #All the xjs in set2. These should all be >= s.\n",
    "    print('xj values from in set1: {}, cutpoint = {}, xj values from in set1: {}'.format(xj_set1, s, xj_set2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exs[0,:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's working!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def recursive_binary_split(examples, max_leaf_population, predictors_to_split_indices='all', cutpoints='equal_space_grid', grid_step_number=10):\n",
    "def recursive_binary_split(examples, max_leaf_population, predictors_to_split_indices='all', grid_step_number=10):\n",
    "    '''\n",
    "    Recursively splits the examples array, building a decision tree with binary splits and stopping when every leaf contains less than max_leaf_population examples.\n",
    "    ------------\n",
    "    Parameters:\n",
    "    examples is a (# examples, p+1) numpy array where p is the number of predictors. The last column contains the responses.\n",
    "    predictors_to_split_indices is a list containing the indices of the predictors we want to split. It can also be the string 'all', in which case we split all the predictors.\n",
    "    #cutpoints is a (len(predictors_to_split_indices, ) array ... It can also be the string ...\n",
    "    '''\n",
    "    p = len(examples[0, :-1]) #Number of predictos.\n",
    "    if predictors_to_split == 'all':\n",
    "        predictors_to_split_indices = range(p) #List with indices of predictors to split.\n",
    "    for j in predictors_to_split_indices:\n",
    "        max_cutpoint =  max(examples[:, j]) + 1 #+1 because we want to allow for splits with all points \"on the left\".\n",
    "        min_cutpoint =  min(examples[:, j])  # no need for -1 here because of the < when splitting.\n",
    "        cutpoints = range(min_cutpoint, max_cutpoint+1, grid_step_number)\n",
    "        for s in cutpoints:\n",
    "            pass\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing a decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the Networkx module maybe...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 3],\n",
       "       [1, 6]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([[1,2,3],[1,5,6]])\n",
    "a[:, np.array([True, False, True])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False,  True])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.logical_not(np.array([True, False]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

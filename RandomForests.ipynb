{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Decision trees and Random forests to predict Hearts diseases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pprint import pprint, pformat\n",
    "import logging\n",
    "logging.basicConfig(level=logging.DEBUG, format='%(message)s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will build a simple logging function to make debugging easier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "global logger\n",
    "logger = logging.getLogger()\n",
    "def log(*args, separator=' ', logger=logger):\n",
    "    '''\n",
    "    Logs args into the console using logger, separating them by separator.\n",
    "    A logger must be defined externally.\n",
    "    '''\n",
    "    str_args = [str(arg) for arg in args]\n",
    "    string = separator.join(str_args)\n",
    "    logger.debug(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[[1. 0.]\n",
      " [0. 1.]] 1\n"
     ]
    }
   ],
   "source": [
    "logger.disabled = False\n",
    "#Example:\n",
    "a = np.eye(2)\n",
    "b = 1\n",
    "log(a,b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing and visualizing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.read_csv("
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Make a tree constructor based on the algorithm from fig. 18.5 of [Norvig] and/or algorithm 8.1 of [Gareth].\n",
    "2. Allow for both categorical and continuous variables: maybe ask the user to specify what variables are continuous and how many splits to perform on each step. Sklearn does not handle categorical variables super easily, so this can actually be useful. Decide on a stopping criterion, maybe even allow for different ones.\n",
    "3. Understand why pruning works as [Hastie] says and using [Breiman], and then implement it as [Hastie] describes.\n",
    "4. Apply to the data. Maybe even apply on only two variables first and plot the regions as [Gareth] does for the Hitters data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression trees [Gareth]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_split(examples, predictor_to_split_idx, cutpoint):\n",
    "    '''\n",
    "    examples is a (# examples, p+1) numpy array where p is the number of predictors. The last column contains the responses.\n",
    "    Splits the predictor_to_split in two at cutpoint.\n",
    "    Returns a tuple with two (, p+1) numpy arrays of examples:\n",
    "        1: examples whose predictor_to_split is < cutpoint.\n",
    "        2: examples whose predictor_to_split is >= cutpoint.\n",
    "    '''\n",
    "    predictors_to_split = examples[:, predictor_to_split_idx] #Column vector with the value for the predictor to split for all the examples.\n",
    "    mask = predictors_to_split < cutpoint #Boolean mask with True values where predictor to split < cutpoint.\n",
    "    set1 = examples[mask, :]\n",
    "    set2 = examples[np.logical_not(mask), :] #Selects the examples where predictor to split >= cutpoint.\n",
    "    return set1, set2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Small test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xj values from in set1: [], cutpoint = 1, xj values from in set1: [2 5]\n",
      "xj values from in set1: [2], cutpoint = 3, xj values from in set1: [5]\n",
      "xj values from in set1: [2], cutpoint = 5, xj values from in set1: [5]\n"
     ]
    }
   ],
   "source": [
    "exs = np.array([[1,2,3],[1,5,6]])\n",
    "j = 1 #index of the split variable\n",
    "cutpoints = [1, 3, 5]\n",
    "for s in cutpoints:\n",
    "    set1, set2 = binary_split(exs, j, s)\n",
    "    xj_set1 = set1[:, j] #All the xjs in set1. These should all be < s.\n",
    "    xj_set2 = set2[:, j] #All the xjs in set2. These should all be >= s.\n",
    "    print('xj values from in set1: {}, cutpoint = {}, xj values from in set1: {}'.format(xj_set1, s, xj_set2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exs[0,:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's working!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimal_binary_split(examples, predictors_to_split_indices, grid_step_number=10, debug_prints=False):\n",
    "    '''\n",
    "    Splits the examples array at the best cutpoint and using the best predictor.\n",
    "    ------------\n",
    "    Parameters:\n",
    "    examples is a (# examples, p+1) numpy array where p is the number of predictors. The last column contains the responses.\n",
    "    predictors_to_split_indices is a list containing the indices of the predictors we want to split. It can also be the string 'all', in which case we split all the predictors.\n",
    "    #cutpoints is a (len(predictors_to_split_indices, ) array ... It can also be the string ...\n",
    "    '''\n",
    "    ###Set up logger\n",
    "    global logger\n",
    "    if debug_prints:\n",
    "        logger.disabled = False\n",
    "    else:\n",
    "        logger.disabled = True #Must write this explicitly to not have problems when running inside other functions.\n",
    "    ###\n",
    "    p = len(examples[0, :-1]) #Number of predictors.\n",
    "    smallest_cost = 100000\n",
    "    best_split = (0, 0, smallest_cost) #placeholder for best_split.\n",
    "    for j in predictors_to_split_indices:\n",
    "        #Construct array of cutpoints:\n",
    "        max_cutpoint =  max(examples[:, j]) \n",
    "        step = (max_cutpoint - min(examples[:,j]))/grid_step_number #grid step\n",
    "        min_cutpoint =  min(examples[:, j]) + step  #We do not want to include min(examples[:,j]) itself, since that would lead to cases with no points 'on the left' because of how binary_split() was defined.\n",
    "        if min_cutpoint == max_cutpoint: #Examples have the same jth predictor value, so no split can be made, so we abort the split.\n",
    "            log('Skip j = {}'.format(j))\n",
    "            continue #Goes to the top of this loop again.\n",
    "        cutpoints = np.linspace(min_cutpoint, max_cutpoint, grid_step_number) \n",
    "        log('Cutpoints for j={}: {}, step: {}'.format(j, cutpoints, step))\n",
    "        for s in cutpoints:\n",
    "            set1, set2 = binary_split(examples, j, s)\n",
    "            log('s,j: {}, {} \\n set1 --- set2: {} --- {}'.format(s,j, set1, set2))\n",
    "            y_1 = set1[:, p]; y_2 = set2[:, p] #Extract the responses.\n",
    "            y1_estimate = np.average(y_1); y2_estimate = np.average(y_2) #Estimates will simply be the averages.\n",
    "            cost = np.sum(np.square(y_1 - y1_estimate)) + np.sum(np.square(y_2 - y2_estimate))\n",
    "            if cost < smallest_cost:\n",
    "                log('NEW COST: {}'.format(cost))\n",
    "                smallest_cost = cost\n",
    "                best_split = (j, s, smallest_cost) #Store info about this iteration.\n",
    "    return best_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skip j = 0\n",
      "Cutpoints for j=1: [2.3 2.6 2.9 3.2 3.5 3.8 4.1 4.4 4.7 5. ], step: 0.3\n",
      "s,j: 2.3, 1 \n",
      " set1 --- set2: [[1 2 8]] --- [[1 4 7]\n",
      " [1 5 2]]\n",
      "NEW COST: 12.5\n",
      "s,j: 2.5999999999999996, 1 \n",
      " set1 --- set2: [[1 2 8]] --- [[1 4 7]\n",
      " [1 5 2]]\n",
      "s,j: 2.9, 1 \n",
      " set1 --- set2: [[1 2 8]] --- [[1 4 7]\n",
      " [1 5 2]]\n",
      "s,j: 3.2, 1 \n",
      " set1 --- set2: [[1 2 8]] --- [[1 4 7]\n",
      " [1 5 2]]\n",
      "s,j: 3.5, 1 \n",
      " set1 --- set2: [[1 2 8]] --- [[1 4 7]\n",
      " [1 5 2]]\n",
      "s,j: 3.8, 1 \n",
      " set1 --- set2: [[1 2 8]] --- [[1 4 7]\n",
      " [1 5 2]]\n",
      "s,j: 4.1, 1 \n",
      " set1 --- set2: [[1 4 7]\n",
      " [1 2 8]] --- [[1 5 2]]\n",
      "NEW COST: 0.5\n",
      "s,j: 4.4, 1 \n",
      " set1 --- set2: [[1 4 7]\n",
      " [1 2 8]] --- [[1 5 2]]\n",
      "s,j: 4.7, 1 \n",
      " set1 --- set2: [[1 4 7]\n",
      " [1 2 8]] --- [[1 5 2]]\n",
      "s,j: 5.0, 1 \n",
      " set1 --- set2: [[1 4 7]\n",
      " [1 2 8]] --- [[1 5 2]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Examples: \n",
      " [[1 4 7]\n",
      " [1 5 2]\n",
      " [1 2 8]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1, 4.1, 0.5)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Example.\n",
    "exs = np.array([[1,4,7],[1,5,2],[1,2,8]])\n",
    "print('Examples: \\n {}'.format(exs))\n",
    "p = len(exs[0, :-1]) #Number of predictors.\n",
    "predictors_to_split_indices = range(p) #List with indices of predictors to split.\n",
    "optimal_binary_split(exs, predictors_to_split_indices, debug_prints=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the function behaves as expected, clumping together the first and third rows, which indeed have the closest response values 7 and 8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recursive_binary_split(examples, max_leaf_population, predictors_to_split_indices='all', grid_step_number=10, debug_prints=False, deep_debug_prints = False):\n",
    "    '''\n",
    "    Recursively splits the examples array, building a decision tree with binary splits and stopping when every leaf contains less than max_leaf_population examples.\n",
    "    ------------\n",
    "    Parameters:\n",
    "    examples is a (# examples, p+1) numpy array where p is the number of predictors. The last column contains the responses.\n",
    "    predictors_to_split_indices is a list containing the indices of the predictors we want to split. It can also be the string 'all', in which case we split all the predictors.\n",
    "    #cutpoints is a (len(predictors_to_split_indices, ) array ... It can also be the string ...\n",
    "    '''\n",
    "    ###Set up logger\n",
    "    global logger\n",
    "    if debug_prints:\n",
    "        logger.disabled = False\n",
    "    else:\n",
    "        logger.disabled = True #Must write this explicitly to not have problems when running inside other functions.\n",
    "    logger_bool = logger.disabled\n",
    "    ###\n",
    "    p = len(examples[0, :-1]) #Number of predictors.\n",
    "    if predictors_to_split_indices == 'all':\n",
    "        predictors_to_split_indices = range(p) #List with indices of predictors to split.\n",
    "    regions = [examples] #Initialize list of all regions. Notice that these regions also include the responses.\n",
    "    tree_log = [regions]\n",
    "    top_leaf_population = len(examples[:,0])\n",
    "    while top_leaf_population >= max_leaf_population:\n",
    "        #Select best region to make split, and split parameters.\n",
    "        splits_info = [((idx, region), optimal_binary_split(region, predictors_to_split_indices, grid_step_number=grid_step_number, debug_prints=deep_debug_prints)) for (idx,region) in enumerate(regions) if region.shape[0]>0] #The if statement ensures there's at least one example. Want to allow for this eentually!\n",
    "        logger.disabled = logger_bool #Restore logger.disable (may have been changed by optimal_binary_split()).\n",
    "        #Find best split.\n",
    "        costs = [info[1][2] for info in splits_info] #info[1] is tuple (j,s,smallest_cost)\n",
    "        min_idx = np.argmin(costs)\n",
    "        best_split = splits_info[min_idx] #Tuple ((idx, region), (j,s,cost))\n",
    "        #We now make the actual split.\n",
    "        idx_region, region = best_split[0]\n",
    "        j = best_split[1][0]\n",
    "        s = best_split[1][1]\n",
    "        R1, R2 = binary_split(region, j, s)\n",
    "        #Substitute region by R1, R2.\n",
    "        del regions[idx_region]\n",
    "        regions.extend([R1, R2])\n",
    "        #Update log and leaf pop:\n",
    "        tree_log.append(regions)\n",
    "        top_leaf_population = max([len(region[:,0]) for region in regions])\n",
    "        log('Current max leaf population: {}'.format(top_leaf_population))\n",
    "    return regions, tree_log\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Current max leaf population: 2\n",
      "Current max leaf population: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Examples: \n",
      " [[1 4 7]\n",
      " [1 5 2]\n",
      " [1 2 8]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[1, 5, 2]]), array([[1, 2, 8]]), array([[1, 4, 7]])]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Example.\n",
    "exs = np.array([[1,4,7],[1,5,2],[1,2,8]])\n",
    "print('Examples: \\n {}'.format(exs))\n",
    "recursive_binary_split(exs, 2, debug_prints=True)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tree prunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing a decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the Networkx module maybe...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

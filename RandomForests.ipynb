{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Decision trees and Random forests to predict Hearts diseases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pprint import pprint, pformat\n",
    "import logging\n",
    "logging.basicConfig(level=logging.DEBUG, format='%(message)s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will build a simple logging function to make debugging easier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "global logger\n",
    "logger = logging.getLogger()\n",
    "def log(*args, separator=' ', logger=logger):\n",
    "    '''\n",
    "    Logs args into the console using logger, separating them by separator.\n",
    "    A logger must be defined externally.\n",
    "    '''\n",
    "    str_args = [str(arg) for arg in args]\n",
    "    string = separator.join(str_args)\n",
    "    logger.debug(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[[1. 0.]\n",
      " [0. 1.]] 1\n"
     ]
    }
   ],
   "source": [
    "logger.disabled = False\n",
    "#Example:\n",
    "a = np.eye(2)\n",
    "b = 1\n",
    "log(a,b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>RestBP</th>\n",
       "      <th>Chol</th>\n",
       "      <th>Fbs</th>\n",
       "      <th>RestECG</th>\n",
       "      <th>MaxHR</th>\n",
       "      <th>ExAng</th>\n",
       "      <th>Oldpeak</th>\n",
       "      <th>Slope</th>\n",
       "      <th>Ca</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>299.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>152.000000</td>\n",
       "      <td>54.438944</td>\n",
       "      <td>0.679868</td>\n",
       "      <td>131.689769</td>\n",
       "      <td>246.693069</td>\n",
       "      <td>0.148515</td>\n",
       "      <td>0.990099</td>\n",
       "      <td>149.607261</td>\n",
       "      <td>0.326733</td>\n",
       "      <td>1.039604</td>\n",
       "      <td>1.600660</td>\n",
       "      <td>0.672241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>87.612784</td>\n",
       "      <td>9.038662</td>\n",
       "      <td>0.467299</td>\n",
       "      <td>17.599748</td>\n",
       "      <td>51.776918</td>\n",
       "      <td>0.356198</td>\n",
       "      <td>0.994971</td>\n",
       "      <td>22.875003</td>\n",
       "      <td>0.469794</td>\n",
       "      <td>1.161075</td>\n",
       "      <td>0.616226</td>\n",
       "      <td>0.937438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>94.000000</td>\n",
       "      <td>126.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>76.500000</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>211.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>133.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>152.000000</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>130.000000</td>\n",
       "      <td>241.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>153.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>227.500000</td>\n",
       "      <td>61.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>140.000000</td>\n",
       "      <td>275.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>166.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>77.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>564.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>202.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.200000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0         Age         Sex      RestBP        Chol         Fbs  \\\n",
       "count  303.000000  303.000000  303.000000  303.000000  303.000000  303.000000   \n",
       "mean   152.000000   54.438944    0.679868  131.689769  246.693069    0.148515   \n",
       "std     87.612784    9.038662    0.467299   17.599748   51.776918    0.356198   \n",
       "min      1.000000   29.000000    0.000000   94.000000  126.000000    0.000000   \n",
       "25%     76.500000   48.000000    0.000000  120.000000  211.000000    0.000000   \n",
       "50%    152.000000   56.000000    1.000000  130.000000  241.000000    0.000000   \n",
       "75%    227.500000   61.000000    1.000000  140.000000  275.000000    0.000000   \n",
       "max    303.000000   77.000000    1.000000  200.000000  564.000000    1.000000   \n",
       "\n",
       "          RestECG       MaxHR       ExAng     Oldpeak       Slope          Ca  \n",
       "count  303.000000  303.000000  303.000000  303.000000  303.000000  299.000000  \n",
       "mean     0.990099  149.607261    0.326733    1.039604    1.600660    0.672241  \n",
       "std      0.994971   22.875003    0.469794    1.161075    0.616226    0.937438  \n",
       "min      0.000000   71.000000    0.000000    0.000000    1.000000    0.000000  \n",
       "25%      0.000000  133.500000    0.000000    0.000000    1.000000    0.000000  \n",
       "50%      1.000000  153.000000    0.000000    0.800000    2.000000    0.000000  \n",
       "75%      2.000000  166.000000    1.000000    1.600000    2.000000    1.000000  \n",
       "max      2.000000  202.000000    1.000000    6.200000    3.000000    3.000000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heart_data = pd.read_csv('Heart.csv')\n",
    "heart_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>ChestPain</th>\n",
       "      <th>RestBP</th>\n",
       "      <th>Chol</th>\n",
       "      <th>Fbs</th>\n",
       "      <th>RestECG</th>\n",
       "      <th>MaxHR</th>\n",
       "      <th>ExAng</th>\n",
       "      <th>Oldpeak</th>\n",
       "      <th>Slope</th>\n",
       "      <th>Ca</th>\n",
       "      <th>Thal</th>\n",
       "      <th>AHD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>typical</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>fixed</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>67</td>\n",
       "      <td>1</td>\n",
       "      <td>asymptomatic</td>\n",
       "      <td>160</td>\n",
       "      <td>286</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>108</td>\n",
       "      <td>1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>67</td>\n",
       "      <td>1</td>\n",
       "      <td>asymptomatic</td>\n",
       "      <td>120</td>\n",
       "      <td>229</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>129</td>\n",
       "      <td>1</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>reversable</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>nonanginal</td>\n",
       "      <td>130</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>nontypical</td>\n",
       "      <td>130</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Age  Sex     ChestPain  RestBP  Chol  Fbs  RestECG  MaxHR  \\\n",
       "0           1   63    1       typical     145   233    1        2    150   \n",
       "1           2   67    1  asymptomatic     160   286    0        2    108   \n",
       "2           3   67    1  asymptomatic     120   229    0        2    129   \n",
       "3           4   37    1    nonanginal     130   250    0        0    187   \n",
       "4           5   41    0    nontypical     130   204    0        2    172   \n",
       "\n",
       "   ExAng  Oldpeak  Slope   Ca        Thal  AHD  \n",
       "0      0      2.3      3  0.0       fixed   No  \n",
       "1      1      1.5      2  3.0      normal  Yes  \n",
       "2      1      2.6      2  2.0  reversable  Yes  \n",
       "3      0      3.5      3  0.0      normal   No  \n",
       "4      0      1.4      1  0.0      normal   No  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heart_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Make a tree constructor based on the algorithm from fig. 18.5 of [Norvig] and/or algorithm 8.1 of [Gareth].\n",
    "2. Allow for both categorical and continuous variables: maybe ask the user to specify what variables are continuous and how many splits to perform on each step. Sklearn does not handle categorical variables super easily, so this can actually be useful. Decide on a stopping criterion, maybe even allow for different ones.\n",
    "3. Understand why pruning works as [Hastie] says and using [Breiman], and then implement it as [Hastie] describes.\n",
    "4. Apply to the data. Maybe even apply on only two variables first and plot the regions as [Gareth] does for the Hitters data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression trees [Gareth]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_split(examples, predictor_to_split_idx, cutpoint):\n",
    "    '''\n",
    "    Performs a binary split on the examples array.\n",
    "    ------------\n",
    "    Parameters:\n",
    "    examples is a (# examples, p+1) numpy array where p is the number of predictors. The last column contains the responses.\n",
    "    Splits the predictor_to_split in two at cutpoint.\n",
    "    ------------\n",
    "    Returns a tuple with two (, p+1) numpy arrays of examples:\n",
    "        1: examples whose predictor_to_split is < cutpoint.\n",
    "        2: examples whose predictor_to_split is >= cutpoint.\n",
    "    '''\n",
    "    predictors_to_split = examples[:, predictor_to_split_idx] #Column vector with the value for the predictor to split for all the examples.\n",
    "    mask = predictors_to_split < cutpoint #Boolean mask with True values where predictor to split < cutpoint.\n",
    "    set1 = examples[mask, :]\n",
    "    set2 = examples[np.logical_not(mask), :] #Selects the examples where predictor to split >= cutpoint.\n",
    "    return set1, set2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Small test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xj values from in set1: [], cutpoint = 1, xj values from in set1: [2 5]\n",
      "xj values from in set1: [2], cutpoint = 3, xj values from in set1: [5]\n",
      "xj values from in set1: [2], cutpoint = 5, xj values from in set1: [5]\n"
     ]
    }
   ],
   "source": [
    "exs = np.array([[1,2,3],[1,5,6]])\n",
    "j = 1 #index of the split variable\n",
    "cutpoints = [1, 3, 5]\n",
    "for s in cutpoints:\n",
    "    set1, set2 = binary_split(exs, j, s)\n",
    "    xj_set1 = set1[:, j] #All the xjs in set1. These should all be < s.\n",
    "    xj_set2 = set2[:, j] #All the xjs in set2. These should all be >= s.\n",
    "    print('xj values from in set1: {}, cutpoint = {}, xj values from in set1: {}'.format(xj_set1, s, xj_set2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exs[0,:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's working!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimal_binary_split(examples, predictors_to_split_indices, grid_step_number=10, debug_prints=False):\n",
    "    '''\n",
    "    Splits the examples array at the best cutpoint and using the best predictor.\n",
    "    ------------\n",
    "    Parameters:\n",
    "    examples is a (# examples, p+1) numpy array where p is the number of predictors. The last column contains the responses.\n",
    "    predictors_to_split_indices is a list containing the indices of the predictors we want to split. It can also be the string 'all', in which case we split all the predictors.\n",
    "    ------------\n",
    "    Returns:\n",
    "    Tuple (j, s, smallest_cost):\n",
    "        1) index of the predictor that was split.\n",
    "        2) chosen cutpoint for the split.\n",
    "        3) cost of the chosen (thus optimal) split.\n",
    "    '''\n",
    "    ###Set up logger\n",
    "    global logger\n",
    "    if debug_prints:\n",
    "        logger.disabled = False\n",
    "    else:\n",
    "        logger.disabled = True #Must write this explicitly to not have problems when running inside other functions.\n",
    "    ###\n",
    "    p = len(examples[0, :-1]) #Number of predictors.\n",
    "    smallest_cost = 100000\n",
    "    best_split = (0, 0, smallest_cost) #placeholder for best_split.\n",
    "    for j in predictors_to_split_indices:\n",
    "        #Construct array of cutpoints:\n",
    "        max_cutpoint =  max(examples[:, j]) \n",
    "        step = (max_cutpoint - min(examples[:,j]))/grid_step_number #grid step\n",
    "        min_cutpoint =  min(examples[:, j]) + step  #We do not want to include min(examples[:,j]) itself, since that would lead to cases with no points 'on the left' because of how binary_split() was defined.\n",
    "        if min_cutpoint == max_cutpoint: #Examples have the same jth predictor value, so no split can be made, so we abort the split.\n",
    "            log('Skip j = {}'.format(j))\n",
    "            continue #Goes to the top of this loop again.\n",
    "        cutpoints = np.linspace(min_cutpoint, max_cutpoint, grid_step_number) \n",
    "        log('Cutpoints for j={}: {}, step: {}'.format(j, cutpoints, step))\n",
    "        for s in cutpoints:\n",
    "            set1, set2 = binary_split(examples, j, s)\n",
    "            log('s,j: {}, {} \\n set1 --- set2: {} --- {}'.format(s,j, set1, set2))\n",
    "            y_1 = set1[:, p]; y_2 = set2[:, p] #Extract the responses.\n",
    "            y1_estimate = np.average(y_1); y2_estimate = np.average(y_2) #Estimates will simply be the averages.\n",
    "            cost = np.sum(np.square(y_1 - y1_estimate)) + np.sum(np.square(y_2 - y2_estimate))\n",
    "            if cost < smallest_cost:\n",
    "                log('NEW COST: {}'.format(cost))\n",
    "                smallest_cost = cost\n",
    "                best_split = (j, s, smallest_cost) #Store info about this iteration.\n",
    "    return best_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skip j = 0\n",
      "Cutpoints for j=1: [2.3 2.6 2.9 3.2 3.5 3.8 4.1 4.4 4.7 5. ], step: 0.3\n",
      "s,j: 2.3, 1 \n",
      " set1 --- set2: [[1 2 8]] --- [[1 4 7]\n",
      " [1 5 2]]\n",
      "NEW COST: 12.5\n",
      "s,j: 2.5999999999999996, 1 \n",
      " set1 --- set2: [[1 2 8]] --- [[1 4 7]\n",
      " [1 5 2]]\n",
      "s,j: 2.9, 1 \n",
      " set1 --- set2: [[1 2 8]] --- [[1 4 7]\n",
      " [1 5 2]]\n",
      "s,j: 3.2, 1 \n",
      " set1 --- set2: [[1 2 8]] --- [[1 4 7]\n",
      " [1 5 2]]\n",
      "s,j: 3.5, 1 \n",
      " set1 --- set2: [[1 2 8]] --- [[1 4 7]\n",
      " [1 5 2]]\n",
      "s,j: 3.8, 1 \n",
      " set1 --- set2: [[1 2 8]] --- [[1 4 7]\n",
      " [1 5 2]]\n",
      "s,j: 4.1, 1 \n",
      " set1 --- set2: [[1 4 7]\n",
      " [1 2 8]] --- [[1 5 2]]\n",
      "NEW COST: 0.5\n",
      "s,j: 4.4, 1 \n",
      " set1 --- set2: [[1 4 7]\n",
      " [1 2 8]] --- [[1 5 2]]\n",
      "s,j: 4.7, 1 \n",
      " set1 --- set2: [[1 4 7]\n",
      " [1 2 8]] --- [[1 5 2]]\n",
      "s,j: 5.0, 1 \n",
      " set1 --- set2: [[1 4 7]\n",
      " [1 2 8]] --- [[1 5 2]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Examples: \n",
      " [[1 4 7]\n",
      " [1 5 2]\n",
      " [1 2 8]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1, 4.1, 0.5)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Example.\n",
    "exs = np.array([[1,4,7],[1,5,2],[1,2,8]])\n",
    "print('Examples: \\n {}'.format(exs))\n",
    "p = len(exs[0, :-1]) #Number of predictors.\n",
    "predictors_to_split_indices = range(p) #List with indices of predictors to split.\n",
    "optimal_binary_split(exs, predictors_to_split_indices, debug_prints=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the function behaves as expected, clumping together the first and third rows, which indeed have the closest response values 7 and 8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recursive_binary_split(examples, max_leaf_population, predictors_to_split_indices='all', grid_step_number=10, debug_prints=False, deep_debug_prints = False):\n",
    "    '''\n",
    "    Recursively splits the examples array, building a decision tree with binary splits and stopping when every leaf contains less than max_leaf_population examples.\n",
    "    ------------\n",
    "    Parameters:\n",
    "    examples is a (# examples, p+1) numpy array where p is the number of predictors. The last column contains the responses.\n",
    "    predictors_to_split_indices is a list containing the indices of the predictors we want to split. It can also be the string 'all', in which case we split all the predictors.\n",
    "    ------------\n",
    "    Returns:\n",
    "    Tuple (regions, tree_log):\n",
    "        1) List of regions obtained after the splitting. Each 'region' is an array of examples.\n",
    "        2) A log of the construction of the tree. Concretely: a list whose entries are the regions lists at the end of each iteration.\n",
    "    '''\n",
    "    ###Set up logger\n",
    "    global logger\n",
    "    if debug_prints:\n",
    "        logger.disabled = False\n",
    "    else:\n",
    "        logger.disabled = True #Must write this explicitly to not have problems when running inside other functions.\n",
    "    logger_bool = logger.disabled\n",
    "    ###\n",
    "    p = len(examples[0, :-1]) #Number of predictors.\n",
    "    if predictors_to_split_indices == 'all':\n",
    "        predictors_to_split_indices = range(p) #List with indices of predictors to split.\n",
    "    regions = [examples] #Initialize list of all regions. Notice that these regions also include the responses.\n",
    "    tree_log = [regions]\n",
    "    top_leaf_population = len(examples[:,0])\n",
    "    while top_leaf_population >= max_leaf_population:\n",
    "        #Select best region to make split, and split parameters.\n",
    "        splits_info = [((idx, region), optimal_binary_split(region, predictors_to_split_indices, grid_step_number=grid_step_number, debug_prints=deep_debug_prints)) for (idx,region) in enumerate(regions) if region.shape[0]>0] #The if statement ensures there's at least one example. Want to allow for this eentually!\n",
    "        logger.disabled = logger_bool #Restore logger.disable (may have been changed by optimal_binary_split()).\n",
    "        #Find best split.\n",
    "        costs = [info[1][2] for info in splits_info] #info[1] is tuple (j,s,smallest_cost)\n",
    "        min_idx = np.argmin(costs)\n",
    "        best_split = splits_info[min_idx] #Tuple ((idx, region), (j,s,cost))\n",
    "        #We now make the actual split.\n",
    "        idx_region, region = best_split[0]\n",
    "        j = best_split[1][0]\n",
    "        s = best_split[1][1]\n",
    "        R1, R2 = binary_split(region, j, s)\n",
    "        #Substitute region by R1, R2.\n",
    "        del regions[idx_region]\n",
    "        regions.extend([R1, R2])\n",
    "        #Update log and leaf pop:\n",
    "        tree_log.append(regions)\n",
    "        top_leaf_population = max([len(region[:,0]) for region in regions])\n",
    "        log('Current max leaf population: {}'.format(top_leaf_population))\n",
    "    return regions, tree_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Current max leaf population: 2\n",
      "Current max leaf population: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Examples: \n",
      " [[1 4 7]\n",
      " [1 5 2]\n",
      " [1 2 8]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[1, 5, 2]]), array([[1, 2, 8]]), array([[1, 4, 7]])]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Example.\n",
    "exs = np.array([[1,4,7],[1,5,2],[1,2,8]])\n",
    "print('Examples: \\n {}'.format(exs))\n",
    "recursive_binary_split(exs, 2, debug_prints=True)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tree prunning [Hastie]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tree $T_0$ created using recursive binary split will probably overfit. The strategy is to simplify the model by finding an appropriate subtree $T$ of $T_0$ by pruning $T$ using *cost-complexity-pruning*, which we'll briefly explain here.\n",
    "\n",
    "The *cost complexity criterion* is defined by\n",
    "$$\n",
    "C_\\alpha(T) = \\sum_{m=1}^{\\vert T \\vert} \\sum_{i\\in I_m} (y_i - \\hat{y}_{R_m})^2 + \\alpha \\vert T \\vert\n",
    "$$\n",
    "\n",
    "where $\\vert T \\vert$ is the number of leaves of $T$, $I_m$ is the indexing set of the region $R_m$ (*i.e.* $R_m = \\{x_i \\in \\text{examples}: i\\in I_m\\}$), $\\hat{y}_{R_m}$ is the predicted response in $R_m$ (in our case $\\hat{y}_{R_m}$ is just the mean $\\mu_{R_m}$), and $\\alpha\\in \\mathbb{R}^+$ controls the size of the tree."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now want to find the subtree $T_\\alpha\\subseteq T_0$ that minimizes $C_\\alpha(T)$. Notice that for $\\alpha = 0$ the minimizing subtree is $T_0$ itself, thus justifying the notation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be shown [Breiman] that for all $\\alpha\\in\\mathbb{R}^+$ there is a unique smallest subtree $T_\\alpha$ that minimizes the cost complexity criterion, and to find it one can use *weakest link pruning*: starting from the bottom (the leaves) of the tree $T_0$, undo the split which has less impact on the cost complexity criterion, obtaining a subtree; keep doing this until you're left only with the root of the tree.\n",
    "\n",
    "This gives us a sequence of subtrees of $T_0$, and it turns out [Breiman] that this sequence must contain $T_\\alpha$.\n",
    "\n",
    "This means that we can simply implement weakest link pruning to obtain a sequence of subtrees and find the one which minimizes $C_\\alpha$. That subtree must be $T_\\alpha$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost_complexity_criterion(alpha, regions):\n",
    "    '''\n",
    "    alpha >= 0. regions is\n",
    "    '''\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weakest_link_pruning():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost_complexity_pruning():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing a decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the Networkx module maybe...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References:\n",
    "\n",
    "1. [Hastie]  \n",
    "2. [Norvig]\n",
    "3. [Gareth]\n",
    "4. [Breiman]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
